{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nx1ZIFazsDA9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 - Linear Regression Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation of mock data \n",
    "\n",
    "Suppose the independent variable $x$ and the response variable $y$ follow a linear relationship, i.e.:\n",
    "\n",
    "$$ y  = \\mathbf{\\beta}^\\top \\cdot \\mathbf{x} = \\beta_0 + \\beta_1 x$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\mathbf{\\beta}\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "\\beta_0 \\\\\n",
    "\\beta_1\n",
    "\\end{bmatrix} \n",
    "\\text{     and,    } \n",
    "\\mathbf{x}\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "1 \\\\\n",
    "x\n",
    "\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "\n",
    "$\\beta_0$ is the intercept term and $\\beta_1$ is the slope term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create some mock data $(X,Y)$ of $N=1000$ data points with certain amount of Gaussian noise $\\epsilon \\sim \\mathcal{N} (0,1) $.\n",
    "\n",
    "\n",
    "Where \n",
    "\n",
    "$$\n",
    "X\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{x_1}, \n",
    "\\mathbf{x_2}, \n",
    "\\cdots,\n",
    "\\mathbf{x_N}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1 & 1& & 1\\\\\n",
    "& &\\cdots &\\\\\n",
    "x_1 & x_2& & x_N\n",
    "\\end{bmatrix}\n",
    "\\text{         and ,     }\n",
    "Y\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "y_1,\n",
    "y_2,\n",
    "\\cdots,\n",
    "y_N\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and\n",
    "\n",
    "$$ y_i = \\mathbf{\\beta}^\\top \\cdot \\mathbf{x}_i + \\epsilon_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i $$ for $i=1 \\ldots N$\n",
    "\n",
    "\n",
    "Let's assume $\\beta_0 = 3$ and $\\beta_1 = 10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "mTVqxx2BsO7t",
    "outputId": "7fc940f7-3cac-4d47-e709-ff6a7dfabeee"
   },
   "outputs": [],
   "source": [
    "N = 1000 #sample size\n",
    "\n",
    "true_beta = np.array([3,10])\n",
    "x = np.linspace(-1,1,N)\n",
    "x1 = np.vstack([np.ones(x.shape), x])\n",
    "\n",
    "eps = np.random.normal(0,1,N)\n",
    "\n",
    "y = np.matmul(true_beta, x1) + eps\n",
    "\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we know $x$ and $y$ follow a linear relationship, but we do not know the value of $\\mathbf{\\beta}$. \n",
    "We want to build a linear model $f(\\mathbf{x}; \\beta)$ and estimate the value of $\\mathbf{\\beta}$ from data samples $(x_i,y_i)$, so that given any input $\\mathbf{x}_i$, we can make a prediction $\\hat{y_i}$:\n",
    "\n",
    "\n",
    "$$ \\hat{y_i} = f(\\mathbf{x}_i; \\beta) = \\mathbf{\\beta}^\\top \\cdot \\mathbf{x}_i  = \\beta_0 + \\beta_1 x_i  $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the mean squared error loss function which measure the error between our predictions and the actual values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7g8A-Cb6svF"
   },
   "source": [
    "$$ l = \\frac{1}{N} \\sum_{i=1}^{N} (y_i-\\hat{y_i})^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can estimate the value of $\\beta$ by finding the minimizer which minimizes $l$ using the Newton-Raphson algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{\\hat{\\beta}}\n",
    "=\n",
    "\\text{argmin}_\\beta \\   l(\\beta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient and Hessian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the Newton-Raphson algorithm, we need to calculate the gradient and Hessian of the loss function, which are the first order and second order partial derivatives of the loss function respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first order partial derivatives of the loss function are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial l}{\\partial \\beta_0} &= -\\frac{2}{N} \\sum_{i=1}^N (y_i-\\hat{y_i}) \\\\\n",
    "\\frac{\\partial l}{\\partial \\beta_1} &= -\\frac{2}{N} \\sum_{i=1}^N x_i \\cdot (y_i-\\hat{y_i}) \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The gradient of the loss function is: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\nabla l\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "\\frac{\\partial l}{\\partial \\beta_0} \\\\ \n",
    "\\frac{\\partial l}{\\partial \\beta_1}\n",
    "\\end{bmatrix}\n",
    "= \n",
    "-2 \\cdot\n",
    "\\begin{bmatrix} \n",
    "\\frac{1}{N} \\sum_{i=1}^N (y_i -\\hat{y_i}) \\\\ \n",
    "\\frac{1}{N} \\sum_{i=1}^N x_i \\cdot (y_i -\\hat{y_i})\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The second order partial derivatives of the loss function are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "\\begin{align}\n",
    "\\frac{\\partial^2 l}{\\partial \\beta_0^2} &= 2 \\\\\n",
    "\\frac{\\partial^2 l}{\\partial \\beta_1^2} &=  \\frac{2}{N} \\sum_{i=1}^N x_i^2 \\\\\n",
    "\\frac{\\partial^2 l}{\\partial \\beta_0 \\partial \\beta_1}  \n",
    "&=  \n",
    "\\frac{\\partial^2 l}{\\partial \\beta_1 \\partial \\beta_0}\n",
    "=\n",
    "\\frac{2}{N} \\sum_{i=1}^N x_i \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Hessian of the loss function is: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "H \n",
    "= \n",
    "\\begin{bmatrix} \n",
    "\\frac{\\partial^2 l}{\\partial \\beta_0^2} & \\frac{\\partial^2 l}{\\partial \\beta_0 \\partial \\beta_1} \\\\ \\frac{\\partial^2 l}{\\partial \\beta_1 \\partial \\beta_0} & \\frac{\\partial^2 l}{\\partial \\beta_1^2} \n",
    "\\end{bmatrix} \n",
    "= \n",
    "2 \\cdot\n",
    "\\begin{bmatrix}\n",
    "1 & \\frac{1}{N} \\sum_{i=1}^N x_i \\\\\n",
    "\\frac{1}{N} \\sum_{i=1}^N x_i & \\frac{1}{N} \\sum_{i=1}^N x_i^2\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHy-SEHM3Nd7"
   },
   "source": [
    "## Newton-Raphson Algorithm (2nd Order Optimization)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the functions for our linear model and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DrghUjgCtJ52"
   },
   "outputs": [],
   "source": [
    "# Define the function for our linear model\n",
    "def model(param,x1):\n",
    "    return\n",
    "\n",
    "# Define the function for our loss function\n",
    "def loss_func(param, x1, y): \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jN03rwVr6qsN"
   },
   "source": [
    "Newton-Raphson algorithm:\n",
    "\n",
    "1. Initialize $\\mathbf{\\beta}$ by sampling from the standard normal distribution  $\\mathcal{N} (0,1)$ \n",
    "\n",
    "\n",
    "\n",
    "2. At each iteration $k$, update the parameters $\\mathbf{\\beta}$ by this equation: \\\n",
    "   $$ \\mathbf{\\beta_{k+1}} = \\mathbf{\\beta_k} - H^{-1} \\mathbf{\\nabla} l(\\beta_k) $$\n",
    "     \n",
    "     \n",
    "3. Stop the algorithm when $|l(\\beta_{k+1}) - l(\\beta_k)| < \\text{tolerance}$, we can use a small number, i.e. $10^{-7}$, as our tolerance value \n",
    "\n",
    "\n",
    "Hint:\n",
    "1. You can use np.abs(delta) to compute the absolute value of delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "qIDLrQvmu9hy",
    "outputId": "694c213e-9ced-43b0-e14c-d7c524e62b0f"
   },
   "outputs": [],
   "source": [
    "beta = np.random.normal(0,1,2) #initialize beta\n",
    "tol = 1e-7 #toloerance\n",
    "delta = 1 #a variable to store the value for l(\\beta_{k+1}) - l(\\beta_{k}), initialized to be 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "id": "xIXU02pRu9jy",
    "outputId": "cb9b7e97-7290-4170-dac5-6568835c9cfc"
   },
   "outputs": [],
   "source": [
    "print('The estimated value for beta is:', beta)\n",
    "print('The true value for beta is:', true_beta)\n",
    "\n",
    "y_pred = np.matmul(beta,x1)\n",
    "\n",
    "plt.plot(x, y_pred, 'r')\n",
    "plt.scatter(x,y)\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_eEc80S_4y4p"
   },
   "source": [
    "## Gradient Descent Algorithm (1st Order Optimization) [Optional Exercise]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWziMZP96hSH"
   },
   "source": [
    "Gradient descent algorithm:\n",
    "\n",
    "\n",
    "1. Initialize $\\mathbf{\\beta}$ by sampling from the standard normal distribution  $\\mathcal{N} (0,1)$ \n",
    "\n",
    "\n",
    "\n",
    "2. At each iteration $k$, update the parameters $\\mathbf{\\beta}$ by this equation: \\\n",
    "   $$ \\mathbf{\\beta_{k+1}} = \\mathbf{\\beta_k} - \\alpha \\mathbf{\\nabla} l(\\beta_k) $$\n",
    "   where $\\alpha \\sim 10^{-1}$ is the step size\n",
    "\n",
    "\n",
    "\n",
    "3. Stop the algorithm when $|l(\\beta_{k+1}) - l(\\beta_k)| < \\text{tolerance}$, we can use a small number, i.e. $10^{-7}$, as our tolerance value \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pWPNUYyAxm8q",
    "outputId": "b9e8fb27-f39c-4b2d-cac9-b2fda707b6e4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "beta = np.random.normal(0,1,2)\n",
    "\n",
    "alpha = 3e-1\n",
    "tol = 1e-7\n",
    "delta = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "id": "hmG0WtzI5C0N",
    "outputId": "f44eede9-3dcb-4974-b2ea-1738e3a2d23b"
   },
   "outputs": [],
   "source": [
    "print('The estimated value for beta is:', beta)\n",
    "print('The true value for beta is:', true_beta)\n",
    "\n",
    "y_pred = np.matmul(beta,x1)\n",
    "\n",
    "plt.plot(x, y_pred, 'r')\n",
    "plt.scatter(x,y)\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "linear_regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
